{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f174834e-beea-4e22-b36f-b2a6acf694e9",
   "metadata": {},
   "source": [
    "# 3. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa006bca",
   "metadata": {},
   "source": [
    "Paper reference:\n",
    "*  https://ieeexplore.ieee.org/abstract/document/6503286/\n",
    "* K. M. Thilina, K. W. Choi, N. Saquib and E. Hossain, \"Pattern classification techniques for cooperative spectrum sensing in cognitive radio networks: SVM and W-KNN approaches,\" 2012 IEEE Global Communications Conference (GLOBECOM), 2012, pp. 1260-1265, doi: 10.1109/GLOCOM.2012.6503286."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5b580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c489415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling and training packages\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data Preparation packages\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: \n",
      " - partition(X, y, percent_train = 0.8), \n",
      " - Xy_dataloader(X_numpy, y_numpy, batch_size=32)\n"
     ]
    }
   ],
   "source": [
    "%run functions/functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14971cf3-989b-40b8-9517-2a598b002795",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c7a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas_ML_Project_SNR_Minus10\n",
      "Pandas_ML_Project_SNR_Minus15\n",
      "Pandas_ML_Project_SNR_Minus20\n",
      "Pandas_ML_Project_SNR_Minus25\n",
      "Pandas_ML_Project_SNR_Minus5\n",
      "Data loaded\n",
      "Example: X, y = data['Pandas_ML_Project_SNR_Minus5']['x'], data['Pandas_ML_Project_SNR_Minus5']['y']\n"
     ]
    }
   ],
   "source": [
    "%run #0-LoadingData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e7c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['Pandas_ML_Project_SNR_Minus5']['x'], data['Pandas_ML_Project_SNR_Minus5']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ee6bc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e45194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    \n",
    "    def __init__(self, k = 2):\n",
    "        self.k = k\n",
    "        \n",
    "#     def find_best_k(self, X_train, y_train, div, k_range):\n",
    "#         batch_size = int(X_train.shape[0] / div)\n",
    "#         y_hat_arr = np.zeros((len(k_range), div))\n",
    "#         y_hat_probs = np.zeros((len(k_range), div))\n",
    "    \n",
    "#         for k_idx, kneighbor in enumerate(k_range):\n",
    "#             self.k = kneighbor\n",
    "#             for idx, i in enumerate(range(0, X_train.shape[0], batch_size)):\n",
    "#                 X_test2 = X_train[i:i+batch_size]\n",
    "#                 y_test2 = y_train[i:i+batch_size]\n",
    "#                 X_train2 = np.concatenate((X_train[:i], X_train[i+batch_size:]))\n",
    "#                 y_train2= np.concatenate((y_train[:i], y_train[i+batch_size:]))\n",
    "#                 yhat, yhat_prob = self.predict(X_train2, X_test2, y_train2)\n",
    "#                 acc_correct = yhat == y_test2\n",
    "#                 accuracy = np.sum(acc_correct) / len(y_test2)\n",
    "#                 y_hat_arr[k_idx, idx] = accuracy\n",
    "#                 y_hat_probs[k_idx, idx] = yhat_prob.mean()\n",
    "#         return y_hat_arr, y_hat_probs\n",
    "    \n",
    "    def find_distance(self, X_train, X_test):\n",
    "        #create newaxis simply so that broadcast to all values\n",
    "        dist = X_test[:, np.newaxis, :] - X_train[np.newaxis, :, :]\n",
    "        sq_dist = dist ** 2\n",
    "\n",
    "        #sum across feature dimension, thus axis = 2\n",
    "        summed_dist = sq_dist.sum(axis=2)\n",
    "        sq_dist = np.sqrt(summed_dist)\n",
    "        return sq_dist\n",
    "    \n",
    "\n",
    "    def find_neighbors(self, X_train, X_test, k):\n",
    "        dist = self.find_distance(X_train, X_test)\n",
    "        #return the first k neighbors\n",
    "        neighbors_ix = np.argsort(dist)[:, 0:k]\n",
    "        return neighbors_ix\n",
    "    \n",
    "    \n",
    "    def get_most_common(self, y, k):\n",
    "        y = y[0:k]\n",
    "        count = np.bincount(y)\n",
    "        largest_first = count.argmax()\n",
    "        largest_second = count.argsort()[-2:][0]\n",
    "        if count[largest_first] == count[largest_second]:\n",
    "            y = y[0: k + 1]\n",
    "            return np.bincount(y).argmax(), count[largest_first] /count.sum()\n",
    "        \n",
    "        return np.bincount(y).argmax(), count[largest_first] / count.sum()\n",
    "            \n",
    "    \n",
    "    def predict(self, X_train, X_test, y_train):\n",
    "        neighbors_ix = self.find_neighbors(X_train, X_test, self.k)\n",
    "        self.pred = np.zeros(X_test.shape[0])\n",
    "        self.probs = np.zeros(X_test.shape[0])\n",
    "        for ix, y in enumerate(y_train[neighbors_ix]):\n",
    "            self.pred[ix], self.probs[ix] = self.get_most_common(y, self.k)\n",
    "        return self.pred, self.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05177ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (8000,) (2000, 11) (2000,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "y = y.astype(int)\n",
    "idx, X_train, y_train, X_test, y_test = partition(X, y, percent_train=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917f8be",
   "metadata": {},
   "source": [
    "## 3. Predict for SNR-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7ed982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== SNR Minus5 ===================\n",
      " Accuracy:  1.0\n",
      "---- Classification report ----\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1005\n",
      "           1       1.00      1.00      1.00       995\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "---- Probability score ----\n",
      "Probability:  1.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(k = 2)\n",
    "yhat, yhat_probs = knn.predict(X_train, X_test, y_train)\n",
    "\n",
    "print(\"==================== SNR Minus5 ===================\\n Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "print(\"---- Classification report ----\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "print(\"---- Probability score ----\")\n",
    "print(\"Probability: \", yhat_probs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae67adc3",
   "metadata": {},
   "source": [
    "## 4. Predict for everything SNR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33dd70f",
   "metadata": {},
   "source": [
    "### SNR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26303ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (8000,) (2000, 11) (2000,)\n",
      "==================== SNR Minus10 ===================\n",
      " Accuracy:  0.9875\n",
      "---- Classification report ----\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       998\n",
      "           1       1.00      0.98      0.99      1002\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "---- Probability score ----\n",
      "Probability:  0.9935\n"
     ]
    }
   ],
   "source": [
    "X, y = data['Pandas_ML_Project_SNR_Minus10']['x'], data['Pandas_ML_Project_SNR_Minus10']['y']\n",
    "y = y.astype(int)\n",
    "idx, X_train, y_train, X_test, y_test = partition(X, y, percent_train=0.8)\n",
    "knn = KNN(k = 2)\n",
    "yhat, yhat_probs = knn.predict(X_train, X_test, y_train)\n",
    "\n",
    "print(\"==================== SNR Minus10 ===================\\n Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "print(\"---- Classification report ----\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "print(\"---- Probability score ----\")\n",
    "print(\"Probability: \", yhat_probs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461ac0a",
   "metadata": {},
   "source": [
    "### SNR-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab58c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (8000,) (2000, 11) (2000,)\n",
      "==================== SNR Minus15 ===================\n",
      " Accuracy:  0.725\n",
      "---- Classification report ----\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1021\n",
      "           1       0.80      0.58      0.67       979\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.74      0.72      0.72      2000\n",
      "weighted avg       0.74      0.72      0.72      2000\n",
      "\n",
      "---- Probability score ----\n",
      "Probability:  0.85375\n"
     ]
    }
   ],
   "source": [
    "X, y = data['Pandas_ML_Project_SNR_Minus15']['x'], data['Pandas_ML_Project_SNR_Minus15']['y']\n",
    "y = y.astype(int)\n",
    "idx, X_train, y_train, X_test, y_test = partition(X, y, percent_train=0.8)\n",
    "knn = KNN(k = 2)\n",
    "yhat, yhat_probs = knn.predict(X_train, X_test, y_train)\n",
    "\n",
    "print(\"==================== SNR Minus15 ===================\\n Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "print(\"---- Classification report ----\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "print(\"---- Probability score ----\")\n",
    "print(\"Probability: \", yhat_probs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510f32c",
   "metadata": {},
   "source": [
    "### SNR-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "868dc1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (8000,) (2000, 11) (2000,)\n",
      "==================== SNR Minus20 ===================\n",
      " Accuracy:  0.529\n",
      "---- Classification report ----\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.77      0.62      1009\n",
      "           1       0.55      0.28      0.37       991\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.54      0.53      0.50      2000\n",
      "weighted avg       0.54      0.53      0.50      2000\n",
      "\n",
      "---- Probability score ----\n",
      "Probability:  0.7555\n"
     ]
    }
   ],
   "source": [
    "X, y = data['Pandas_ML_Project_SNR_Minus20']['x'], data['Pandas_ML_Project_SNR_Minus20']['y']\n",
    "y = y.astype(int)\n",
    "idx, X_train, y_train, X_test, y_test = partition(X, y, percent_train=0.8)\n",
    "knn = KNN(k = 2)\n",
    "yhat, yhat_probs = knn.predict(X_train, X_test, y_train)\n",
    "\n",
    "print(\"==================== SNR Minus20 ===================\\n Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "print(\"---- Classification report ----\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "print(\"---- Probability score ----\")\n",
    "print(\"Probability: \", yhat_probs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd126d6",
   "metadata": {},
   "source": [
    "### SNR-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7857e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (8000,) (2000, 11) (2000,)\n",
      "==================== SNR Minus25 ===================\n",
      " Accuracy:  0.507\n",
      "---- Classification report ----\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60       994\n",
      "           1       0.52      0.26      0.35      1006\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.51      0.51      0.48      2000\n",
      "weighted avg       0.51      0.51      0.48      2000\n",
      "\n",
      "---- Probability score ----\n",
      "Probability:  0.75325\n"
     ]
    }
   ],
   "source": [
    "X, y = data['Pandas_ML_Project_SNR_Minus25']['x'], data['Pandas_ML_Project_SNR_Minus25']['y']\n",
    "y = y.astype(int)\n",
    "idx, X_train, y_train, X_test, y_test = partition(X, y, percent_train=0.8)\n",
    "knn = KNN(k = 2)\n",
    "yhat, yhat_probs = knn.predict(X_train, X_test, y_train)\n",
    "\n",
    "print(\"==================== SNR Minus25 ===================\\n Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "print(\"---- Classification report ----\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "print(\"---- Probability score ----\")\n",
    "print(\"Probability: \", yhat_probs.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
